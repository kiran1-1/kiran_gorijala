{"componentChunkName":"component---src-pages-archive-js","path":"/archive/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"date":"2024-10-14","title":"Olympic Data Analysis","tech":["Azure Data Factory","Data Leak","DataBricks","PowerBI"],"github":"","external":"","company":"Project"},"html":"<p>The Olympic Data Analysis project utilized advanced ETL processes with Azure Data Factory, Databricks, and PySpark to analyze historical data, creating interactive Power BI and Tableau dashboards that improved processing time by 30% and data accuracy by 25%.</p>"}},{"node":{"frontmatter":{"date":"2024-09-30","title":"Coronavirus Data Analytics","tech":["Python","Google cloud Storage","Mage","Jupyter notebook","Looker"],"github":"","external":"","company":"Project"},"html":"<p>The Coronavirus Data Analytics project enhanced COVID-19 predictive accuracy by 20% and pipeline efficiency by 30% using machine learning and Google Cloud Storage, while developing real-time Looker dashboards for critical metric visualization.</p>"}},{"node":{"frontmatter":{"date":"2024-09-1","title":"Price Crawler: Inflation Rate Analysis Using Big Data","tech":["Common Crawl Dataset","Python/SQL","Big Data Tools","Batch Processing Systems"],"github":"","external":"","company":"Project"},"html":"<p>This project involves building a data pipeline to calculate inflation rates using online prices of goods and services from the Common Crawl dataset. A sample analysis of laptop prices revealed a 4.8% inflation rate in 2019, more than double the 2.3% reported by the Bureau of Labor Statistics, offering insights for investment strategies and business decision-making.</p>"}},{"node":{"frontmatter":{"date":"2024-08-15","title":"Azure Certified Data Engineer","tech":["Azure Data Factory(ADF)","Azure Databricks","Azure Synapse Analytics","Azure Data Lake Storage (ADLS)"],"github":"","external":"https://learn.microsoft.com/api/credentials/share/en-us/GorijalaKiran-4164/7C10E2A9A93ABA14?sharingId=803ADB08CD3AA393","company":"Certification"},"html":"<p>The Microsoft Certified: Azure Data Engineer Associate certification validates my expertise in designing and implementing data solutions on Azure, including data integration, transformation, and storage. It demonstrates proficiency in tools like Azure Data Factory, Synapse Analytics, and Databricks to support scalable and secure data solutions.</p>"}},{"node":{"frontmatter":{"date":"2024-08-15","title":"AWS Certified Data Engineer","tech":["AWS Glue","Databricks","AWS Redshift"],"github":"","external":"https://www.credly.com/badges/900151e9-52f6-43f3-b827-0a13a220df21","company":"Certification"},"html":"<p>The AWS Certified Data Engineer – Associate certification validates my expertise in building and maintaining data pipelines on AWS. It demonstrates proficiency in designing scalable, secure, and cost-optimized data solutions using services like AWS Glue, Amazon Redshift, Amazon S3, AWS Lambda, and Amazon Kinesis. This certification highlights my ability to manage data ingestion, transformation, storage, and analytics across distributed systems on the AWS cloud platform.</p>"}},{"node":{"frontmatter":{"date":"2024-07-30","title":"Reddit Data Pipeline Engineering","tech":["Docker","Postgr SQL","AWS Glue","AWS S3","AWS Athena","Redshift Data Warehousing"],"github":"","external":"","company":"Project"},"html":"<p>The Reddit Data Engineering project implements an end-to-end ETL pipeline to extract, transform, and load Reddit data into an Amazon Redshift data warehouse. It leverages tools like Apache Airflow, AWS Glue, and Docker to create a scalable and efficient data engineering workflow.</p>"}},{"node":{"frontmatter":{"date":"2024-07-01","title":"Realtime Socket Streaming","tech":["TCP/IP Socket","Apache Spark","Kafka","Elasticsearch","Kibana, Power BI, Tableau"],"github":"","external":"","company":"Project"},"html":"<p>This project builds a real-time data pipeline that acquires data over TCP/IP sockets, processes it using Apache Spark with sentiment analysis from ChatGPT4, streams it via Kafka, and replicates it in Elasticsearch for advanced querying and visualization. It offers insights through tools like Kibana, Power BI, and Tableau, ensuring seamless data flow and analysis.</p>"}},{"node":{"frontmatter":{"date":"2023-11-20","title":"Accident Severity prediction","tech":["Pyspark","Machine learning","hadoop","PowerBI"],"github":"","external":"","company":"Project"},"html":"<p>Built a predictive model to classify accident severity based on factors such as weather conditions, road features, and traffic data.</p>"}},{"node":{"frontmatter":{"date":"2021-08-20","title":"Open Data Visualizer","tech":["Flask","Python","Matplotlib","file handling"],"github":"","external":"http://www.ijcrt.org/papers/IJCRT2105661.pdf","company":"Project"},"html":"<p>The Open Data Visualizer is an application that allows users to upload any dataset and automatically generates comprehensive insights and visualizations. It simplifies data exploration and analysis through an intuitive, user-friendly frontend interface.</p>"}},{"node":{"frontmatter":{"date":"2020-08-01","title":"Grocery Store","tech":["C++","MySql","Dijkstra's Algorithm","Knapsack Algorithm"],"github":"","external":"","company":"Project"},"html":"<p>The Grocery Store project involves creating an application for a grocery chain in India, enabling users to efficiently order groceries. By leveraging Dijkstra’s algorithm, it identifies the nearest stores, while the Knapsack algorithm optimizes order selections, significantly enhancing user experience and efficiency.</p>"}}]}},"pageContext":{}},"staticQueryHashes":["1994492073","2009693873","2031412112","3825832676"],"slicesMap":{}}